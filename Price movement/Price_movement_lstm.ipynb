{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM Model for price movement"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from sklearn.metrics import classification_report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def rename_datetime(data):\n",
    "    data.rename(columns={'Unnamed: 0': 'datetime'},inplace=True)\n",
    "    data['datetime']=pd.to_datetime(data['datetime'])\n",
    "    data.set_index('datetime', inplace=True)\n",
    "    return data\n",
    "# feature selection\n",
    "# create features\n",
    "def create_features(data, g_lag, tv_lag, tw_lag):\n",
    "    data['Change'] =data['Close'].diff().dropna()\n",
    "    data['Label'] = np.where(data['Change']>0, 1 ,0)\n",
    "    data['google_trends_lag']=data['google_trends'].shift(g_lag)\n",
    "    data['tweet_volume_lag']=data['tweet_volume'].shift(tv_lag)\n",
    "    data['tw_polarity_lag'] = data['tw_polarity'].shift(tw_lag)\n",
    "    data['volume_lag']=data['Volume'].shift(4)\n",
    "    data['tw_score_lag']=data['tw_compound'].shift(10)\n",
    "    data['re_co_lag']=data['re_compound'].shift(3)\n",
    "    data['re_po_lag']=data['re_polarity'].shift(10)\n",
    "    data['re_su_lag']=data['re_subjectivity'].shift(3)\n",
    "    # data.drop(columns=['Open','High','Low'],inplace=True)\n",
    "    # Add features like RSI? Moving average?\n",
    "\n",
    "    data.dropna(inplace=True)\n",
    "    return data\n",
    "# keep the wanted features\n",
    "def keep_features(feature_conditions):\n",
    "    features=['Label','Close']\n",
    "    for feature, condition in feature_conditions.items():\n",
    "        if condition:\n",
    "            features.append(feature)\n",
    "    print(features)\n",
    "    return features\n",
    "\n",
    "# create the lagged features based on the timesteps\n",
    "def reshape_features(data, to_keep=1, to_remove=1):\n",
    "    variables = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    columns, names = list(), list()\n",
    "\n",
    "    for i in range(to_keep, 0, -1):\n",
    "        columns.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(variables)]\n",
    "\n",
    "    for i in range(0, to_remove):\n",
    "        columns.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(variables)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(variables)]\n",
    "\n",
    "    #put it all together\n",
    "    final = pd.concat(columns, axis=1)\n",
    "    final.columns = names\n",
    "\n",
    "    #drop rows with NaN values\n",
    "    final.dropna(inplace=True)\n",
    "\n",
    "    new_data = final.reset_index()\n",
    "\n",
    "    new_data = new_data.drop(columns=['datetime'])\n",
    "\n",
    "    return new_data\n",
    "\n",
    "# shuffle the data\n",
    "def shuffle_data(times, data):\n",
    "    np.random.seed(1)\n",
    "    for i in range(times+1):\n",
    "        data=shuffle(data)\n",
    "    return data\n",
    "\n",
    "# split labels from data\n",
    "def split_label(train, test):\n",
    "    train_y = train['var1(t)'].values\n",
    "    test_y = test['var1(t)'].values\n",
    "    train_y = train_y.reshape(len(train_y), 1)\n",
    "    test_y = test_y.reshape(len(test_y), 1)\n",
    "    return train_y, test_y\n",
    "\n",
    "# normalize data using Minmaxscaler\n",
    "def normalize_reshape_data(train, test, train_y, test_y, all_features, n_features, timestep):\n",
    "    feature_scaler=MinMaxScaler()\n",
    "    scale_train_data=feature_scaler.fit_transform(train)\n",
    "    scale_test_data= feature_scaler.transform(test)\n",
    "    train = scale_train_data[:, :all_features]\n",
    "    test = scale_test_data[:, :all_features]\n",
    "    #keep only prices array\n",
    "    train_X, train_y = train[:, :all_features], train_y[:, -1]\n",
    "    test_X, test_y = test[:, :all_features], test_y[:, -1]\n",
    "    # reshape the data\n",
    "    train_X = train_X.reshape((train_X.shape[0], timestep, n_features))\n",
    "    test_X = test_X.reshape((test_X.shape[0], timestep, n_features))\n",
    "    #set labels for training data to categorical\n",
    "    train_y = to_categorical(train_y, 2)\n",
    "\n",
    "    return train_X, test_X, train_y, test_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "filepath='./../data/processed_data.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_data(filepath, g_lag, tv_lag, tw_lag, timestep, shuffle_times, split_ratio, feature_conditions, month, flag):\n",
    "    # import data\n",
    "    # import the original data. processed_data\n",
    "    # processed_data: weighted reddit score+ fill the nan data\n",
    "    data=pd.read_csv(filepath)\n",
    "    # show the data\n",
    "    data=rename_datetime(data)\n",
    "\n",
    "    # get the subdata set\n",
    "    if flag==0:\n",
    "        data=data[data.index.month==month]\n",
    "    else:\n",
    "        data=data[(data.index.month>=1) & (data.index.month <=month)]\n",
    "\n",
    "    # create features\n",
    "    data_created = create_features(data,g_lag,tv_lag,tw_lag)\n",
    "\n",
    "    # keep the wanted features\n",
    "    features = keep_features(feature_conditions)\n",
    "    data=data_created[features]\n",
    "\n",
    "    # reshape the data\n",
    "    # create the lagged features based on the timesteps\n",
    "    df_copy = data.copy()\n",
    "    new_data=reshape_features(df_copy, timestep, 1)\n",
    "\n",
    "    # shuffle the data\n",
    "    shuffled_data=shuffle_data(shuffle_times, new_data)\n",
    "\n",
    "    # split the data\n",
    "    train, test= train_test_split(shuffled_data, test_size=split_ratio)\n",
    "    train_y, test_y=split_label(train, test)\n",
    "\n",
    "    # normalized the data using MinMaxscaler\n",
    "    n_features=len(features)\n",
    "    all_features = timestep * n_features\n",
    "    if (all_features==0):\n",
    "        all_features=n_features\n",
    "    train_X, test_X, train_y, test_y =normalize_reshape_data(train, test, train_y, test_y, all_features, n_features,timestep)\n",
    "\n",
    "    print(\"train_X Shape:\", train_X.shape)\n",
    "    print(\"train_y Shape:\", train_y.shape)\n",
    "    print(\"test_X Shape:\", test_X.shape)\n",
    "    print(\"test_y Shape:\", test_y.shape)\n",
    "\n",
    "    return data, train_X, test_X, train_y, test_y, n_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# # get correlation matrix\n",
    "# sns.heatmap(data.corr(), annot=True)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Building"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def create_model(neurons, epochs, dropout, batch_size, verbose, layers,\n",
    "                 activ_func, activ_dense,my_optimizer,\n",
    "                 train_X, train_y, test_X, test_y, n_features, timestep ):\n",
    "    #set seed to reproduce results\n",
    "    np.random.seed(1)\n",
    "    tf.random.set_seed(1)\n",
    "\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "\n",
    "    #return sequences flag if there are more than 1 layer\n",
    "    return_seq = layers > 1\n",
    "\n",
    "    #add first layer\n",
    "    model.add(LSTM(neurons, return_sequences=return_seq, input_shape=(timestep, n_features), activation=activ_func))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    #add the other layers\n",
    "    for i in range(1, layers):\n",
    "        ret_seq = i != (layers-1)\n",
    "        model.add(LSTM(neurons, return_sequences=ret_seq, activation=activ_func))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    #add a dense layer to output the prediction\n",
    "    model.add(Dense(2, activation=activ_dense))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=my_optimizer, metrics=['accuracy'])\n",
    "\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience =50)\n",
    "\n",
    "    # fit network\n",
    "    history = model.fit(train_X, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose, shuffle=False,validation_split=0.2, callbacks=[callback])\n",
    "\n",
    "    #reshape\n",
    "    test_X = test_X.reshape((test_X.shape[0], timestep, n_features))\n",
    "\n",
    "    #make prediction\n",
    "    pred = model.predict(test_X)\n",
    "\n",
    "    #reshape again\n",
    "    test_X = test_X.reshape((test_X.shape[0], timestep* n_features,))\n",
    "\n",
    "    #get prediction\n",
    "    y_pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    # calculate the metrics\n",
    "    report=classification_report(\n",
    "          test_y,\n",
    "          y_pred,target_names = [\"Down\", \"Up\"],\n",
    "          digits = 5, output_dict=True)\n",
    "\n",
    "    # precision = report['Down']['precision']\n",
    "    down_f1_score = report['Down']['f1-score']\n",
    "    up_f1_score = report['Up']['f1-score']\n",
    "    accuracy=report['accuracy']\n",
    "\n",
    "    return down_f1_score, up_f1_score, accuracy,model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# model parameters\n",
    "import os\n",
    "feature_conditions = {\n",
    "        'google_trends': 0, 'google_trends_lag': 0,\n",
    "        'tweet_volume_lag': 0, 'tw_polarity_lag': 0, 'tw_compound': 0,\n",
    "        'tw_polarity': 0, 'tweet_volume': 0,'re_compound': 0,'re_polarity': 0,\n",
    "        're_subjectivity': 0\n",
    "    }\n",
    "def test_model(filepath_out, feature_conditions):\n",
    "    columns = [\"timestep\",\"features\",\"google_trends_lag\",\"tweet_volume_lag\",\"tweet_polarity_score_lag\", \"batch_size\", \"neurons\", \"layers\", \"mean_down_f1_score\",\"mean_up_f1_score\", \"mean_acc\",\"min_acc\", \"max_acc\", \"diff_acc\",\"optimizer\",\"month\",\"consecutive\",\"actic_func\"]\n",
    "\n",
    "    try:\n",
    "        results = pd.read_csv(filepath_out)\n",
    "    except:\n",
    "        results = pd.DataFrame(columns=columns)\n",
    "\n",
    "    #lagged_features\n",
    "    timestep = [10]\n",
    "    #train_ratio\n",
    "    split_ratio =0.2\n",
    "    shuffle_times = 3\n",
    "    activ_func = \"linear\"\n",
    "    activ_dense = 'softmax'\n",
    "    my_optimizer = 'adam'\n",
    "    # my_optimizer=RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=0.0)\n",
    "    epochs = 10000\n",
    "    months =[6]\n",
    "     #for each lag feature\n",
    "    for month in months:\n",
    "        for step in timestep:\n",
    "            neurons = [32]\n",
    "            layers = [1]\n",
    "            batch_sizes = [200]\n",
    "            dropout = 0.25\n",
    "            verbose=2\n",
    "            # Lags\n",
    "            g_lag = [2]\n",
    "            tv_lag = [28] # tweets volume\n",
    "            tw_lag = 4 # tweets score\n",
    "\n",
    "            # set flag: 1 - consecutive months, flag: 0 - single month\n",
    "            flag=1\n",
    "\n",
    "            #for each epoch, neuron, layers and batch_size value\n",
    "            for n in neurons:\n",
    "                for l in layers:\n",
    "                    for b in  batch_sizes:\n",
    "                        print(\"Testing model: lag:\", timestep, \", neurons:\", n, \", layers:\", l, \", batch_size:\", b)\n",
    "                        for g in g_lag:\n",
    "                            for tv in tv_lag:\n",
    "                                #run for 5 times\n",
    "                                accuracies = []\n",
    "                                down_f1_score =[]\n",
    "                                up_f1_score = []\n",
    "                                models=[]\n",
    "                                for i in range (0,5):\n",
    "                                    data, train_X, test_X, train_y, test_y, n_features = get_data(filepath, g, tv, tw_lag, step, shuffle_times, split_ratio, feature_conditions,month,flag)\n",
    "                                    down_score, up_score, accuracy,model = create_model(n, epochs, dropout, b, verbose, l, activ_func, activ_dense,my_optimizer, train_X, train_y, test_X, test_y, n_features, step)\n",
    "                                    accuracies.append(accuracy)\n",
    "                                    down_f1_score.append(down_score)\n",
    "                                    up_f1_score.append(up_score)\n",
    "                                    models.append(model)\n",
    "\n",
    "                                #calculate mean values\n",
    "                                accuracies = np.array(accuracies)\n",
    "                                max_index=np.argmin(accuracies)\n",
    "                                # Define a path to save the model\n",
    "                                model_path = 'saved_models/6_base_lstm_model.h5'\n",
    "\n",
    "                                # Create the directory if it doesn't exist\n",
    "                                os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "\n",
    "                                #  Save the model\n",
    "                                models[max_index].save(model_path)\n",
    "                                print(\"Model saved successfully.\")\n",
    "                                mean_acc =accuracies.mean()\n",
    "                                min_acc =accuracies.min()\n",
    "                                max_acc =accuracies.max()\n",
    "                                diff_acc = max_acc - min_acc\n",
    "                                mean_down_f1_score= np.array(down_f1_score).mean()\n",
    "                                mean_up_f1_score=np.array(up_f1_score).mean()\n",
    "\n",
    "                                results = results.append({\"timestep\": step,\"features\": data.columns.values,\"google_trends_lag\":g,\"tweet_volume_lag\": tv,\"tweet_polarity_score_lag\": tw_lag, \"batch_size\":b, \"neurons\":n, \"layers\":l, \"mean_down_f1_score\":mean_down_f1_score,\"mean_up_f1_score\":mean_up_f1_score, \"mean_acc\": mean_acc,\"min_acc\":min_acc, \"max_acc\":max_acc, \"diff_acc\": diff_acc,\"optimizer\":my_optimizer,\"month\":month,\"consecutive\": flag,\"actic_func\":activ_func}, ignore_index=True)\n",
    "    return pd.DataFrame(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model: lag: [10] , neurons: 32 , layers: 1 , batch_size: 200\n",
      "['Label', 'Close']\n",
      "train_X Shape: (3444, 10, 2)\n",
      "train_y Shape: (3444, 2)\n",
      "test_X Shape: (862, 10, 2)\n",
      "test_y Shape: (862,)\n",
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 20:27:19.114550: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 - 1s - loss: 0.6948 - accuracy: 0.5132 - val_loss: 0.6928 - val_accuracy: 0.5109 - 575ms/epoch - 41ms/step\n",
      "Epoch 2/10000\n",
      "14/14 - 0s - loss: 0.6937 - accuracy: 0.5122 - val_loss: 0.6929 - val_accuracy: 0.5225 - 67ms/epoch - 5ms/step\n",
      "Epoch 3/10000\n",
      "14/14 - 0s - loss: 0.6918 - accuracy: 0.5154 - val_loss: 0.6930 - val_accuracy: 0.5239 - 67ms/epoch - 5ms/step\n",
      "Epoch 4/10000\n",
      "14/14 - 0s - loss: 0.6911 - accuracy: 0.5158 - val_loss: 0.6926 - val_accuracy: 0.5152 - 68ms/epoch - 5ms/step\n",
      "Epoch 5/10000\n",
      "14/14 - 0s - loss: 0.6928 - accuracy: 0.5060 - val_loss: 0.6928 - val_accuracy: 0.5283 - 69ms/epoch - 5ms/step\n",
      "Epoch 6/10000\n",
      "14/14 - 0s - loss: 0.6912 - accuracy: 0.5289 - val_loss: 0.6930 - val_accuracy: 0.5152 - 67ms/epoch - 5ms/step\n",
      "Epoch 7/10000\n",
      "14/14 - 0s - loss: 0.6923 - accuracy: 0.5205 - val_loss: 0.6927 - val_accuracy: 0.5239 - 61ms/epoch - 4ms/step\n",
      "Epoch 8/10000\n",
      "14/14 - 0s - loss: 0.6910 - accuracy: 0.5260 - val_loss: 0.6930 - val_accuracy: 0.5225 - 66ms/epoch - 5ms/step\n",
      "Epoch 9/10000\n",
      "14/14 - 0s - loss: 0.6904 - accuracy: 0.5379 - val_loss: 0.6930 - val_accuracy: 0.5327 - 67ms/epoch - 5ms/step\n",
      "Epoch 10/10000\n",
      "14/14 - 0s - loss: 0.6912 - accuracy: 0.5274 - val_loss: 0.6931 - val_accuracy: 0.5254 - 67ms/epoch - 5ms/step\n",
      "Epoch 11/10000\n",
      "14/14 - 0s - loss: 0.6911 - accuracy: 0.5143 - val_loss: 0.6934 - val_accuracy: 0.5036 - 67ms/epoch - 5ms/step\n",
      "Epoch 12/10000\n",
      "14/14 - 0s - loss: 0.6912 - accuracy: 0.5267 - val_loss: 0.6932 - val_accuracy: 0.5269 - 68ms/epoch - 5ms/step\n",
      "Epoch 13/10000\n",
      "14/14 - 0s - loss: 0.6912 - accuracy: 0.5216 - val_loss: 0.6933 - val_accuracy: 0.5210 - 70ms/epoch - 5ms/step\n",
      "Epoch 14/10000\n",
      "14/14 - 0s - loss: 0.6906 - accuracy: 0.5336 - val_loss: 0.6935 - val_accuracy: 0.5123 - 68ms/epoch - 5ms/step\n",
      "Epoch 15/10000\n",
      "14/14 - 0s - loss: 0.6900 - accuracy: 0.5256 - val_loss: 0.6937 - val_accuracy: 0.5051 - 66ms/epoch - 5ms/step\n",
      "Epoch 16/10000\n",
      "14/14 - 0s - loss: 0.6896 - accuracy: 0.5354 - val_loss: 0.6937 - val_accuracy: 0.5167 - 65ms/epoch - 5ms/step\n",
      "Epoch 17/10000\n",
      "14/14 - 0s - loss: 0.6901 - accuracy: 0.5328 - val_loss: 0.6937 - val_accuracy: 0.5181 - 66ms/epoch - 5ms/step\n",
      "Epoch 18/10000\n",
      "14/14 - 0s - loss: 0.6896 - accuracy: 0.5390 - val_loss: 0.6939 - val_accuracy: 0.5181 - 65ms/epoch - 5ms/step\n",
      "Epoch 19/10000\n",
      "14/14 - 0s - loss: 0.6900 - accuracy: 0.5310 - val_loss: 0.6941 - val_accuracy: 0.5109 - 67ms/epoch - 5ms/step\n",
      "Epoch 20/10000\n",
      "14/14 - 0s - loss: 0.6902 - accuracy: 0.5347 - val_loss: 0.6942 - val_accuracy: 0.5094 - 66ms/epoch - 5ms/step\n",
      "Epoch 21/10000\n",
      "14/14 - 0s - loss: 0.6902 - accuracy: 0.5314 - val_loss: 0.6944 - val_accuracy: 0.5080 - 66ms/epoch - 5ms/step\n",
      "Epoch 22/10000\n",
      "14/14 - 0s - loss: 0.6883 - accuracy: 0.5368 - val_loss: 0.6943 - val_accuracy: 0.5138 - 69ms/epoch - 5ms/step\n",
      "Epoch 23/10000\n",
      "14/14 - 0s - loss: 0.6893 - accuracy: 0.5387 - val_loss: 0.6948 - val_accuracy: 0.5065 - 65ms/epoch - 5ms/step\n",
      "Epoch 24/10000\n",
      "14/14 - 0s - loss: 0.6897 - accuracy: 0.5412 - val_loss: 0.6947 - val_accuracy: 0.5094 - 67ms/epoch - 5ms/step\n",
      "Epoch 25/10000\n",
      "14/14 - 0s - loss: 0.6894 - accuracy: 0.5245 - val_loss: 0.6949 - val_accuracy: 0.5051 - 66ms/epoch - 5ms/step\n",
      "Epoch 26/10000\n",
      "14/14 - 0s - loss: 0.6881 - accuracy: 0.5361 - val_loss: 0.6949 - val_accuracy: 0.5152 - 66ms/epoch - 5ms/step\n",
      "Epoch 27/10000\n",
      "14/14 - 0s - loss: 0.6891 - accuracy: 0.5459 - val_loss: 0.6950 - val_accuracy: 0.5196 - 69ms/epoch - 5ms/step\n",
      "Epoch 28/10000\n",
      "14/14 - 0s - loss: 0.6890 - accuracy: 0.5495 - val_loss: 0.6951 - val_accuracy: 0.5051 - 69ms/epoch - 5ms/step\n",
      "Epoch 29/10000\n",
      "14/14 - 0s - loss: 0.6903 - accuracy: 0.5267 - val_loss: 0.6949 - val_accuracy: 0.5239 - 62ms/epoch - 4ms/step\n",
      "Epoch 30/10000\n",
      "14/14 - 0s - loss: 0.6881 - accuracy: 0.5463 - val_loss: 0.6950 - val_accuracy: 0.5167 - 68ms/epoch - 5ms/step\n",
      "Epoch 31/10000\n",
      "14/14 - 0s - loss: 0.6900 - accuracy: 0.5318 - val_loss: 0.6950 - val_accuracy: 0.5196 - 65ms/epoch - 5ms/step\n",
      "Epoch 32/10000\n",
      "14/14 - 0s - loss: 0.6889 - accuracy: 0.5368 - val_loss: 0.6950 - val_accuracy: 0.5167 - 66ms/epoch - 5ms/step\n",
      "Epoch 33/10000\n",
      "14/14 - 0s - loss: 0.6878 - accuracy: 0.5350 - val_loss: 0.6955 - val_accuracy: 0.5065 - 65ms/epoch - 5ms/step\n",
      "Epoch 34/10000\n",
      "14/14 - 0s - loss: 0.6898 - accuracy: 0.5423 - val_loss: 0.6951 - val_accuracy: 0.5210 - 69ms/epoch - 5ms/step\n",
      "Epoch 35/10000\n",
      "14/14 - 0s - loss: 0.6892 - accuracy: 0.5368 - val_loss: 0.6951 - val_accuracy: 0.5167 - 68ms/epoch - 5ms/step\n",
      "Epoch 36/10000\n",
      "14/14 - 0s - loss: 0.6890 - accuracy: 0.5336 - val_loss: 0.6953 - val_accuracy: 0.5123 - 67ms/epoch - 5ms/step\n",
      "Epoch 37/10000\n",
      "14/14 - 0s - loss: 0.6896 - accuracy: 0.5267 - val_loss: 0.6953 - val_accuracy: 0.5123 - 65ms/epoch - 5ms/step\n",
      "Epoch 38/10000\n",
      "14/14 - 0s - loss: 0.6893 - accuracy: 0.5408 - val_loss: 0.6953 - val_accuracy: 0.5196 - 69ms/epoch - 5ms/step\n",
      "Epoch 39/10000\n",
      "14/14 - 0s - loss: 0.6883 - accuracy: 0.5365 - val_loss: 0.6953 - val_accuracy: 0.5196 - 65ms/epoch - 5ms/step\n",
      "Epoch 40/10000\n",
      "14/14 - 0s - loss: 0.6896 - accuracy: 0.5328 - val_loss: 0.6957 - val_accuracy: 0.5094 - 65ms/epoch - 5ms/step\n",
      "Epoch 41/10000\n",
      "14/14 - 0s - loss: 0.6894 - accuracy: 0.5347 - val_loss: 0.6953 - val_accuracy: 0.5181 - 66ms/epoch - 5ms/step\n",
      "Epoch 42/10000\n",
      "14/14 - 0s - loss: 0.6893 - accuracy: 0.5347 - val_loss: 0.6954 - val_accuracy: 0.5167 - 65ms/epoch - 5ms/step\n",
      "Epoch 43/10000\n",
      "14/14 - 0s - loss: 0.6887 - accuracy: 0.5325 - val_loss: 0.6953 - val_accuracy: 0.5210 - 66ms/epoch - 5ms/step\n",
      "Epoch 44/10000\n",
      "14/14 - 0s - loss: 0.6898 - accuracy: 0.5372 - val_loss: 0.6960 - val_accuracy: 0.5022 - 67ms/epoch - 5ms/step\n",
      "Epoch 45/10000\n",
      "14/14 - 0s - loss: 0.6885 - accuracy: 0.5372 - val_loss: 0.6957 - val_accuracy: 0.5152 - 67ms/epoch - 5ms/step\n",
      "Epoch 46/10000\n",
      "14/14 - 0s - loss: 0.6886 - accuracy: 0.5365 - val_loss: 0.6955 - val_accuracy: 0.5269 - 90ms/epoch - 6ms/step\n",
      "Epoch 47/10000\n",
      "14/14 - 0s - loss: 0.6894 - accuracy: 0.5303 - val_loss: 0.6959 - val_accuracy: 0.5109 - 108ms/epoch - 8ms/step\n",
      "Epoch 48/10000\n",
      "14/14 - 0s - loss: 0.6898 - accuracy: 0.5281 - val_loss: 0.6956 - val_accuracy: 0.5210 - 105ms/epoch - 8ms/step\n",
      "Epoch 49/10000\n",
      "14/14 - 0s - loss: 0.6892 - accuracy: 0.5372 - val_loss: 0.6960 - val_accuracy: 0.5094 - 77ms/epoch - 5ms/step\n",
      "Epoch 50/10000\n",
      "14/14 - 0s - loss: 0.6888 - accuracy: 0.5437 - val_loss: 0.6959 - val_accuracy: 0.5123 - 74ms/epoch - 5ms/step\n",
      "Epoch 51/10000\n",
      "14/14 - 0s - loss: 0.6886 - accuracy: 0.5379 - val_loss: 0.6960 - val_accuracy: 0.5196 - 75ms/epoch - 5ms/step\n",
      "Epoch 52/10000\n",
      "14/14 - 0s - loss: 0.6890 - accuracy: 0.5405 - val_loss: 0.6960 - val_accuracy: 0.5181 - 72ms/epoch - 5ms/step\n",
      "Epoch 53/10000\n",
      "14/14 - 0s - loss: 0.6895 - accuracy: 0.5408 - val_loss: 0.6961 - val_accuracy: 0.5152 - 69ms/epoch - 5ms/step\n",
      "Epoch 54/10000\n",
      "14/14 - 0s - loss: 0.6886 - accuracy: 0.5397 - val_loss: 0.6961 - val_accuracy: 0.5138 - 69ms/epoch - 5ms/step\n",
      "27/27 [==============================] - 0s 799us/step\n",
      "['Label', 'Close']\n",
      "train_X Shape: (3444, 10, 2)\n",
      "train_y Shape: (3444, 2)\n",
      "test_X Shape: (862, 10, 2)\n",
      "test_y Shape: (862,)\n",
      "Epoch 1/10000\n",
      "14/14 - 1s - loss: 0.6952 - accuracy: 0.4835 - val_loss: 0.6940 - val_accuracy: 0.4906 - 707ms/epoch - 51ms/step\n",
      "Epoch 2/10000\n",
      "14/14 - 0s - loss: 0.6924 - accuracy: 0.5172 - val_loss: 0.6924 - val_accuracy: 0.5239 - 64ms/epoch - 5ms/step\n",
      "Epoch 3/10000\n",
      "14/14 - 0s - loss: 0.6933 - accuracy: 0.5085 - val_loss: 0.6927 - val_accuracy: 0.5196 - 62ms/epoch - 4ms/step\n",
      "Epoch 4/10000\n",
      "14/14 - 0s - loss: 0.6940 - accuracy: 0.5045 - val_loss: 0.6926 - val_accuracy: 0.5181 - 79ms/epoch - 6ms/step\n",
      "Epoch 5/10000\n",
      "14/14 - 0s - loss: 0.6913 - accuracy: 0.5318 - val_loss: 0.6925 - val_accuracy: 0.5254 - 61ms/epoch - 4ms/step\n",
      "Epoch 6/10000\n",
      "14/14 - 0s - loss: 0.6913 - accuracy: 0.5249 - val_loss: 0.6927 - val_accuracy: 0.5152 - 58ms/epoch - 4ms/step\n",
      "Epoch 7/10000\n",
      "14/14 - 0s - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6926 - val_accuracy: 0.5210 - 58ms/epoch - 4ms/step\n",
      "Epoch 8/10000\n",
      "14/14 - 0s - loss: 0.6909 - accuracy: 0.5303 - val_loss: 0.6930 - val_accuracy: 0.5036 - 56ms/epoch - 4ms/step\n",
      "Epoch 9/10000\n",
      "14/14 - 0s - loss: 0.6906 - accuracy: 0.5270 - val_loss: 0.6928 - val_accuracy: 0.5239 - 61ms/epoch - 4ms/step\n",
      "Epoch 10/10000\n",
      "14/14 - 0s - loss: 0.6909 - accuracy: 0.5143 - val_loss: 0.6929 - val_accuracy: 0.5254 - 67ms/epoch - 5ms/step\n",
      "Epoch 11/10000\n",
      "14/14 - 0s - loss: 0.6902 - accuracy: 0.5260 - val_loss: 0.6934 - val_accuracy: 0.5109 - 64ms/epoch - 5ms/step\n",
      "Epoch 12/10000\n",
      "14/14 - 0s - loss: 0.6897 - accuracy: 0.5358 - val_loss: 0.6932 - val_accuracy: 0.5210 - 69ms/epoch - 5ms/step\n",
      "Epoch 13/10000\n",
      "14/14 - 0s - loss: 0.6908 - accuracy: 0.5187 - val_loss: 0.6933 - val_accuracy: 0.5167 - 72ms/epoch - 5ms/step\n",
      "Epoch 14/10000\n",
      "14/14 - 0s - loss: 0.6902 - accuracy: 0.5234 - val_loss: 0.6936 - val_accuracy: 0.5123 - 100ms/epoch - 7ms/step\n",
      "Epoch 15/10000\n",
      "14/14 - 0s - loss: 0.6902 - accuracy: 0.5325 - val_loss: 0.6937 - val_accuracy: 0.5109 - 70ms/epoch - 5ms/step\n",
      "Epoch 16/10000\n",
      "14/14 - 0s - loss: 0.6903 - accuracy: 0.5321 - val_loss: 0.6937 - val_accuracy: 0.5167 - 67ms/epoch - 5ms/step\n",
      "Epoch 17/10000\n",
      "14/14 - 0s - loss: 0.6899 - accuracy: 0.5296 - val_loss: 0.6938 - val_accuracy: 0.5065 - 65ms/epoch - 5ms/step\n",
      "Epoch 18/10000\n",
      "14/14 - 0s - loss: 0.6889 - accuracy: 0.5416 - val_loss: 0.6942 - val_accuracy: 0.5080 - 65ms/epoch - 5ms/step\n",
      "Epoch 19/10000\n",
      "14/14 - 0s - loss: 0.6903 - accuracy: 0.5307 - val_loss: 0.6942 - val_accuracy: 0.5094 - 66ms/epoch - 5ms/step\n",
      "Epoch 20/10000\n",
      "14/14 - 0s - loss: 0.6889 - accuracy: 0.5365 - val_loss: 0.6943 - val_accuracy: 0.5109 - 65ms/epoch - 5ms/step\n",
      "Epoch 21/10000\n",
      "14/14 - 0s - loss: 0.6901 - accuracy: 0.5347 - val_loss: 0.6945 - val_accuracy: 0.5123 - 65ms/epoch - 5ms/step\n",
      "Epoch 22/10000\n",
      "14/14 - 0s - loss: 0.6894 - accuracy: 0.5368 - val_loss: 0.6945 - val_accuracy: 0.5094 - 69ms/epoch - 5ms/step\n",
      "Epoch 23/10000\n",
      "14/14 - 0s - loss: 0.6884 - accuracy: 0.5456 - val_loss: 0.6948 - val_accuracy: 0.5109 - 67ms/epoch - 5ms/step\n",
      "Epoch 24/10000\n",
      "14/14 - 0s - loss: 0.6895 - accuracy: 0.5347 - val_loss: 0.6951 - val_accuracy: 0.5065 - 66ms/epoch - 5ms/step\n",
      "Epoch 25/10000\n",
      "14/14 - 0s - loss: 0.6899 - accuracy: 0.5379 - val_loss: 0.6948 - val_accuracy: 0.5109 - 65ms/epoch - 5ms/step\n",
      "Epoch 26/10000\n",
      "14/14 - 0s - loss: 0.6896 - accuracy: 0.5358 - val_loss: 0.6950 - val_accuracy: 0.5152 - 67ms/epoch - 5ms/step\n",
      "Epoch 27/10000\n",
      "14/14 - 0s - loss: 0.6888 - accuracy: 0.5354 - val_loss: 0.6951 - val_accuracy: 0.5181 - 68ms/epoch - 5ms/step\n",
      "Epoch 28/10000\n",
      "14/14 - 0s - loss: 0.6895 - accuracy: 0.5397 - val_loss: 0.6951 - val_accuracy: 0.5225 - 67ms/epoch - 5ms/step\n",
      "Epoch 29/10000\n",
      "14/14 - 0s - loss: 0.6894 - accuracy: 0.5339 - val_loss: 0.6954 - val_accuracy: 0.5109 - 71ms/epoch - 5ms/step\n",
      "Epoch 30/10000\n",
      "14/14 - 0s - loss: 0.6887 - accuracy: 0.5358 - val_loss: 0.6952 - val_accuracy: 0.5152 - 72ms/epoch - 5ms/step\n",
      "Epoch 31/10000\n",
      "14/14 - 0s - loss: 0.6894 - accuracy: 0.5358 - val_loss: 0.6955 - val_accuracy: 0.5109 - 72ms/epoch - 5ms/step\n",
      "Epoch 32/10000\n",
      "14/14 - 0s - loss: 0.6885 - accuracy: 0.5379 - val_loss: 0.6955 - val_accuracy: 0.5123 - 74ms/epoch - 5ms/step\n",
      "Epoch 33/10000\n",
      "14/14 - 0s - loss: 0.6896 - accuracy: 0.5310 - val_loss: 0.6956 - val_accuracy: 0.5138 - 69ms/epoch - 5ms/step\n",
      "Epoch 34/10000\n",
      "14/14 - 0s - loss: 0.6890 - accuracy: 0.5510 - val_loss: 0.6958 - val_accuracy: 0.5109 - 69ms/epoch - 5ms/step\n",
      "Epoch 35/10000\n",
      "14/14 - 0s - loss: 0.6887 - accuracy: 0.5328 - val_loss: 0.6956 - val_accuracy: 0.5239 - 74ms/epoch - 5ms/step\n",
      "Epoch 36/10000\n",
      "14/14 - 0s - loss: 0.6888 - accuracy: 0.5368 - val_loss: 0.6961 - val_accuracy: 0.5065 - 71ms/epoch - 5ms/step\n",
      "Epoch 37/10000\n",
      "14/14 - 0s - loss: 0.6886 - accuracy: 0.5379 - val_loss: 0.6960 - val_accuracy: 0.5167 - 69ms/epoch - 5ms/step\n",
      "Epoch 38/10000\n",
      "14/14 - 0s - loss: 0.6890 - accuracy: 0.5401 - val_loss: 0.6959 - val_accuracy: 0.5239 - 68ms/epoch - 5ms/step\n",
      "Epoch 39/10000\n",
      "14/14 - 0s - loss: 0.6886 - accuracy: 0.5358 - val_loss: 0.6964 - val_accuracy: 0.5080 - 70ms/epoch - 5ms/step\n",
      "Epoch 40/10000\n",
      "14/14 - 0s - loss: 0.6898 - accuracy: 0.5227 - val_loss: 0.6964 - val_accuracy: 0.5094 - 67ms/epoch - 5ms/step\n",
      "Epoch 41/10000\n",
      "14/14 - 0s - loss: 0.6887 - accuracy: 0.5397 - val_loss: 0.6962 - val_accuracy: 0.5152 - 75ms/epoch - 5ms/step\n",
      "Epoch 42/10000\n",
      "14/14 - 0s - loss: 0.6895 - accuracy: 0.5332 - val_loss: 0.6963 - val_accuracy: 0.5181 - 75ms/epoch - 5ms/step\n",
      "Epoch 43/10000\n",
      "14/14 - 0s - loss: 0.6889 - accuracy: 0.5347 - val_loss: 0.6962 - val_accuracy: 0.5225 - 71ms/epoch - 5ms/step\n",
      "Epoch 44/10000\n",
      "14/14 - 0s - loss: 0.6889 - accuracy: 0.5412 - val_loss: 0.6971 - val_accuracy: 0.5051 - 72ms/epoch - 5ms/step\n",
      "Epoch 45/10000\n",
      "14/14 - 0s - loss: 0.6879 - accuracy: 0.5408 - val_loss: 0.6965 - val_accuracy: 0.5167 - 69ms/epoch - 5ms/step\n",
      "Epoch 46/10000\n",
      "14/14 - 0s - loss: 0.6890 - accuracy: 0.5383 - val_loss: 0.6967 - val_accuracy: 0.5196 - 71ms/epoch - 5ms/step\n",
      "Epoch 47/10000\n",
      "14/14 - 0s - loss: 0.6891 - accuracy: 0.5332 - val_loss: 0.6969 - val_accuracy: 0.5152 - 73ms/epoch - 5ms/step\n",
      "Epoch 48/10000\n",
      "14/14 - 0s - loss: 0.6886 - accuracy: 0.5347 - val_loss: 0.6966 - val_accuracy: 0.5196 - 72ms/epoch - 5ms/step\n",
      "Epoch 49/10000\n",
      "14/14 - 0s - loss: 0.6888 - accuracy: 0.5401 - val_loss: 0.6973 - val_accuracy: 0.5065 - 71ms/epoch - 5ms/step\n",
      "Epoch 50/10000\n",
      "14/14 - 0s - loss: 0.6896 - accuracy: 0.5299 - val_loss: 0.6969 - val_accuracy: 0.5196 - 70ms/epoch - 5ms/step\n",
      "Epoch 51/10000\n",
      "14/14 - 0s - loss: 0.6888 - accuracy: 0.5416 - val_loss: 0.6971 - val_accuracy: 0.5167 - 70ms/epoch - 5ms/step\n",
      "Epoch 52/10000\n",
      "14/14 - 0s - loss: 0.6880 - accuracy: 0.5376 - val_loss: 0.6971 - val_accuracy: 0.5210 - 69ms/epoch - 5ms/step\n",
      "27/27 [==============================] - 0s 792us/step\n",
      "['Label', 'Close']\n",
      "train_X Shape: (3444, 10, 2)\n",
      "train_y Shape: (3444, 2)\n",
      "test_X Shape: (862, 10, 2)\n",
      "test_y Shape: (862,)\n",
      "Epoch 1/10000\n",
      "14/14 - 1s - loss: 0.6918 - accuracy: 0.5292 - val_loss: 0.6923 - val_accuracy: 0.5167 - 762ms/epoch - 54ms/step\n",
      "Epoch 2/10000\n",
      "14/14 - 0s - loss: 0.6907 - accuracy: 0.5303 - val_loss: 0.6930 - val_accuracy: 0.5181 - 77ms/epoch - 6ms/step\n",
      "Epoch 3/10000\n",
      "14/14 - 0s - loss: 0.6909 - accuracy: 0.5234 - val_loss: 0.6931 - val_accuracy: 0.5196 - 74ms/epoch - 5ms/step\n",
      "Epoch 4/10000\n",
      "14/14 - 0s - loss: 0.6916 - accuracy: 0.5285 - val_loss: 0.6929 - val_accuracy: 0.5210 - 127ms/epoch - 9ms/step\n",
      "Epoch 5/10000\n",
      "14/14 - 0s - loss: 0.6901 - accuracy: 0.5191 - val_loss: 0.6933 - val_accuracy: 0.5196 - 88ms/epoch - 6ms/step\n",
      "Epoch 6/10000\n",
      "14/14 - 0s - loss: 0.6908 - accuracy: 0.5205 - val_loss: 0.6931 - val_accuracy: 0.5196 - 79ms/epoch - 6ms/step\n",
      "Epoch 7/10000\n",
      "14/14 - 0s - loss: 0.6903 - accuracy: 0.5325 - val_loss: 0.6932 - val_accuracy: 0.5225 - 80ms/epoch - 6ms/step\n",
      "Epoch 8/10000\n",
      "14/14 - 0s - loss: 0.6906 - accuracy: 0.5372 - val_loss: 0.6936 - val_accuracy: 0.5167 - 82ms/epoch - 6ms/step\n",
      "Epoch 9/10000\n",
      "14/14 - 0s - loss: 0.6902 - accuracy: 0.5318 - val_loss: 0.6934 - val_accuracy: 0.5123 - 79ms/epoch - 6ms/step\n",
      "Epoch 10/10000\n",
      "14/14 - 0s - loss: 0.6910 - accuracy: 0.5209 - val_loss: 0.6936 - val_accuracy: 0.5080 - 73ms/epoch - 5ms/step\n",
      "Epoch 11/10000\n",
      "14/14 - 0s - loss: 0.6893 - accuracy: 0.5270 - val_loss: 0.6940 - val_accuracy: 0.5196 - 70ms/epoch - 5ms/step\n",
      "Epoch 12/10000\n",
      "14/14 - 0s - loss: 0.6896 - accuracy: 0.5419 - val_loss: 0.6939 - val_accuracy: 0.5094 - 69ms/epoch - 5ms/step\n",
      "Epoch 13/10000\n",
      "14/14 - 0s - loss: 0.6905 - accuracy: 0.5318 - val_loss: 0.6940 - val_accuracy: 0.5065 - 68ms/epoch - 5ms/step\n",
      "Epoch 14/10000\n",
      "14/14 - 0s - loss: 0.6891 - accuracy: 0.5394 - val_loss: 0.6940 - val_accuracy: 0.5094 - 67ms/epoch - 5ms/step\n",
      "Epoch 15/10000\n",
      "14/14 - 0s - loss: 0.6899 - accuracy: 0.5314 - val_loss: 0.6942 - val_accuracy: 0.5036 - 133ms/epoch - 10ms/step\n",
      "Epoch 16/10000\n",
      "14/14 - 0s - loss: 0.6890 - accuracy: 0.5343 - val_loss: 0.6944 - val_accuracy: 0.5109 - 68ms/epoch - 5ms/step\n",
      "Epoch 17/10000\n",
      "14/14 - 0s - loss: 0.6902 - accuracy: 0.5376 - val_loss: 0.6944 - val_accuracy: 0.5080 - 67ms/epoch - 5ms/step\n",
      "Epoch 18/10000\n",
      "14/14 - 0s - loss: 0.6887 - accuracy: 0.5390 - val_loss: 0.6945 - val_accuracy: 0.5036 - 66ms/epoch - 5ms/step\n",
      "Epoch 19/10000\n",
      "14/14 - 0s - loss: 0.6905 - accuracy: 0.5285 - val_loss: 0.6945 - val_accuracy: 0.5051 - 68ms/epoch - 5ms/step\n",
      "Epoch 20/10000\n",
      "14/14 - 0s - loss: 0.6899 - accuracy: 0.5325 - val_loss: 0.6946 - val_accuracy: 0.5065 - 68ms/epoch - 5ms/step\n",
      "Epoch 21/10000\n",
      "14/14 - 0s - loss: 0.6896 - accuracy: 0.5383 - val_loss: 0.6946 - val_accuracy: 0.5065 - 65ms/epoch - 5ms/step\n",
      "Epoch 22/10000\n",
      "14/14 - 0s - loss: 0.6881 - accuracy: 0.5456 - val_loss: 0.6947 - val_accuracy: 0.5065 - 64ms/epoch - 5ms/step\n",
      "Epoch 23/10000\n",
      "14/14 - 0s - loss: 0.6881 - accuracy: 0.5477 - val_loss: 0.6949 - val_accuracy: 0.5123 - 67ms/epoch - 5ms/step\n",
      "Epoch 24/10000\n",
      "14/14 - 0s - loss: 0.6889 - accuracy: 0.5441 - val_loss: 0.6950 - val_accuracy: 0.5094 - 71ms/epoch - 5ms/step\n",
      "Epoch 25/10000\n",
      "14/14 - 0s - loss: 0.6894 - accuracy: 0.5434 - val_loss: 0.6951 - val_accuracy: 0.5109 - 67ms/epoch - 5ms/step\n",
      "Epoch 26/10000\n",
      "14/14 - 0s - loss: 0.6890 - accuracy: 0.5368 - val_loss: 0.6950 - val_accuracy: 0.5225 - 71ms/epoch - 5ms/step\n",
      "Epoch 27/10000\n",
      "14/14 - 0s - loss: 0.6887 - accuracy: 0.5372 - val_loss: 0.6953 - val_accuracy: 0.5123 - 72ms/epoch - 5ms/step\n",
      "Epoch 28/10000\n",
      "14/14 - 0s - loss: 0.6888 - accuracy: 0.5405 - val_loss: 0.6955 - val_accuracy: 0.5065 - 71ms/epoch - 5ms/step\n",
      "Epoch 29/10000\n",
      "14/14 - 0s - loss: 0.6875 - accuracy: 0.5448 - val_loss: 0.6957 - val_accuracy: 0.5065 - 74ms/epoch - 5ms/step\n",
      "Epoch 30/10000\n",
      "14/14 - 0s - loss: 0.6883 - accuracy: 0.5412 - val_loss: 0.6955 - val_accuracy: 0.5181 - 75ms/epoch - 5ms/step\n",
      "Epoch 31/10000\n",
      "14/14 - 0s - loss: 0.6910 - accuracy: 0.5281 - val_loss: 0.6957 - val_accuracy: 0.5094 - 71ms/epoch - 5ms/step\n",
      "Epoch 32/10000\n",
      "14/14 - 0s - loss: 0.6881 - accuracy: 0.5325 - val_loss: 0.6956 - val_accuracy: 0.5138 - 68ms/epoch - 5ms/step\n",
      "Epoch 33/10000\n",
      "14/14 - 0s - loss: 0.6889 - accuracy: 0.5379 - val_loss: 0.6956 - val_accuracy: 0.5123 - 67ms/epoch - 5ms/step\n",
      "Epoch 34/10000\n",
      "14/14 - 0s - loss: 0.6903 - accuracy: 0.5354 - val_loss: 0.6958 - val_accuracy: 0.5080 - 66ms/epoch - 5ms/step\n",
      "Epoch 35/10000\n",
      "14/14 - 0s - loss: 0.6894 - accuracy: 0.5296 - val_loss: 0.6955 - val_accuracy: 0.5210 - 66ms/epoch - 5ms/step\n",
      "Epoch 36/10000\n",
      "14/14 - 0s - loss: 0.6888 - accuracy: 0.5347 - val_loss: 0.6958 - val_accuracy: 0.5065 - 64ms/epoch - 5ms/step\n",
      "Epoch 37/10000\n",
      "14/14 - 0s - loss: 0.6885 - accuracy: 0.5412 - val_loss: 0.6957 - val_accuracy: 0.5080 - 65ms/epoch - 5ms/step\n",
      "Epoch 38/10000\n",
      "14/14 - 0s - loss: 0.6884 - accuracy: 0.5401 - val_loss: 0.6957 - val_accuracy: 0.5065 - 65ms/epoch - 5ms/step\n",
      "Epoch 39/10000\n",
      "14/14 - 0s - loss: 0.6894 - accuracy: 0.5387 - val_loss: 0.6958 - val_accuracy: 0.5094 - 72ms/epoch - 5ms/step\n",
      "Epoch 40/10000\n",
      "14/14 - 0s - loss: 0.6897 - accuracy: 0.5314 - val_loss: 0.6958 - val_accuracy: 0.5094 - 67ms/epoch - 5ms/step\n",
      "Epoch 41/10000\n",
      "14/14 - 0s - loss: 0.6893 - accuracy: 0.5390 - val_loss: 0.6958 - val_accuracy: 0.5109 - 67ms/epoch - 5ms/step\n",
      "Epoch 42/10000\n",
      "14/14 - 0s - loss: 0.6889 - accuracy: 0.5423 - val_loss: 0.6957 - val_accuracy: 0.5210 - 62ms/epoch - 4ms/step\n",
      "Epoch 43/10000\n",
      "14/14 - 0s - loss: 0.6896 - accuracy: 0.5412 - val_loss: 0.6958 - val_accuracy: 0.5167 - 65ms/epoch - 5ms/step\n",
      "Epoch 44/10000\n",
      "14/14 - 0s - loss: 0.6891 - accuracy: 0.5347 - val_loss: 0.6960 - val_accuracy: 0.5109 - 68ms/epoch - 5ms/step\n",
      "Epoch 45/10000\n",
      "14/14 - 0s - loss: 0.6891 - accuracy: 0.5387 - val_loss: 0.6960 - val_accuracy: 0.5094 - 69ms/epoch - 5ms/step\n",
      "Epoch 46/10000\n",
      "14/14 - 0s - loss: 0.6887 - accuracy: 0.5408 - val_loss: 0.6960 - val_accuracy: 0.5181 - 64ms/epoch - 5ms/step\n",
      "Epoch 47/10000\n",
      "14/14 - 0s - loss: 0.6890 - accuracy: 0.5401 - val_loss: 0.6962 - val_accuracy: 0.5167 - 64ms/epoch - 5ms/step\n",
      "Epoch 48/10000\n",
      "14/14 - 0s - loss: 0.6898 - accuracy: 0.5336 - val_loss: 0.6964 - val_accuracy: 0.5065 - 65ms/epoch - 5ms/step\n",
      "Epoch 49/10000\n",
      "14/14 - 0s - loss: 0.6888 - accuracy: 0.5383 - val_loss: 0.6964 - val_accuracy: 0.5152 - 65ms/epoch - 5ms/step\n",
      "Epoch 50/10000\n",
      "14/14 - 0s - loss: 0.6890 - accuracy: 0.5358 - val_loss: 0.6964 - val_accuracy: 0.5123 - 64ms/epoch - 5ms/step\n",
      "Epoch 51/10000\n",
      "14/14 - 0s - loss: 0.6882 - accuracy: 0.5379 - val_loss: 0.6966 - val_accuracy: 0.5109 - 64ms/epoch - 5ms/step\n",
      "27/27 [==============================] - 0s 796us/step\n",
      "['Label', 'Close']\n",
      "train_X Shape: (3444, 10, 2)\n",
      "train_y Shape: (3444, 2)\n",
      "test_X Shape: (862, 10, 2)\n",
      "test_y Shape: (862,)\n",
      "Epoch 1/10000\n",
      "14/14 - 1s - loss: 0.6957 - accuracy: 0.4918 - val_loss: 0.6944 - val_accuracy: 0.4891 - 698ms/epoch - 50ms/step\n",
      "Epoch 2/10000\n",
      "14/14 - 0s - loss: 0.6931 - accuracy: 0.4976 - val_loss: 0.6930 - val_accuracy: 0.5080 - 67ms/epoch - 5ms/step\n",
      "Epoch 3/10000\n",
      "14/14 - 0s - loss: 0.6922 - accuracy: 0.5129 - val_loss: 0.6927 - val_accuracy: 0.5065 - 67ms/epoch - 5ms/step\n",
      "Epoch 4/10000\n",
      "14/14 - 0s - loss: 0.6929 - accuracy: 0.5100 - val_loss: 0.6929 - val_accuracy: 0.5225 - 77ms/epoch - 6ms/step\n",
      "Epoch 5/10000\n",
      "14/14 - 0s - loss: 0.6910 - accuracy: 0.5274 - val_loss: 0.6927 - val_accuracy: 0.5254 - 203ms/epoch - 14ms/step\n",
      "Epoch 6/10000\n",
      "14/14 - 0s - loss: 0.6912 - accuracy: 0.5347 - val_loss: 0.6926 - val_accuracy: 0.5254 - 67ms/epoch - 5ms/step\n",
      "Epoch 7/10000\n",
      "14/14 - 0s - loss: 0.6919 - accuracy: 0.5212 - val_loss: 0.6926 - val_accuracy: 0.5254 - 65ms/epoch - 5ms/step\n",
      "Epoch 8/10000\n",
      "14/14 - 0s - loss: 0.6902 - accuracy: 0.5223 - val_loss: 0.6932 - val_accuracy: 0.5036 - 66ms/epoch - 5ms/step\n",
      "Epoch 9/10000\n",
      "14/14 - 0s - loss: 0.6907 - accuracy: 0.5260 - val_loss: 0.6928 - val_accuracy: 0.5239 - 67ms/epoch - 5ms/step\n",
      "Epoch 10/10000\n",
      "14/14 - 0s - loss: 0.6914 - accuracy: 0.5187 - val_loss: 0.6930 - val_accuracy: 0.5269 - 66ms/epoch - 5ms/step\n",
      "Epoch 11/10000\n",
      "14/14 - 0s - loss: 0.6913 - accuracy: 0.5180 - val_loss: 0.6933 - val_accuracy: 0.5210 - 64ms/epoch - 5ms/step\n",
      "Epoch 12/10000\n",
      "14/14 - 0s - loss: 0.6892 - accuracy: 0.5379 - val_loss: 0.6932 - val_accuracy: 0.5269 - 64ms/epoch - 5ms/step\n",
      "Epoch 13/10000\n",
      "14/14 - 0s - loss: 0.6907 - accuracy: 0.5296 - val_loss: 0.6935 - val_accuracy: 0.5181 - 64ms/epoch - 5ms/step\n",
      "Epoch 14/10000\n",
      "14/14 - 0s - loss: 0.6908 - accuracy: 0.5336 - val_loss: 0.6934 - val_accuracy: 0.5210 - 64ms/epoch - 5ms/step\n",
      "Epoch 15/10000\n",
      "14/14 - 0s - loss: 0.6896 - accuracy: 0.5318 - val_loss: 0.6937 - val_accuracy: 0.5167 - 67ms/epoch - 5ms/step\n",
      "Epoch 16/10000\n",
      "14/14 - 0s - loss: 0.6900 - accuracy: 0.5390 - val_loss: 0.6938 - val_accuracy: 0.5196 - 67ms/epoch - 5ms/step\n",
      "Epoch 17/10000\n",
      "14/14 - 0s - loss: 0.6889 - accuracy: 0.5452 - val_loss: 0.6938 - val_accuracy: 0.5181 - 66ms/epoch - 5ms/step\n",
      "Epoch 18/10000\n",
      "14/14 - 0s - loss: 0.6892 - accuracy: 0.5426 - val_loss: 0.6942 - val_accuracy: 0.5138 - 64ms/epoch - 5ms/step\n",
      "Epoch 19/10000\n",
      "14/14 - 0s - loss: 0.6890 - accuracy: 0.5423 - val_loss: 0.6943 - val_accuracy: 0.5167 - 65ms/epoch - 5ms/step\n",
      "Epoch 20/10000\n",
      "14/14 - 0s - loss: 0.6884 - accuracy: 0.5328 - val_loss: 0.6947 - val_accuracy: 0.5080 - 66ms/epoch - 5ms/step\n",
      "Epoch 21/10000\n",
      "14/14 - 0s - loss: 0.6884 - accuracy: 0.5394 - val_loss: 0.6949 - val_accuracy: 0.5109 - 67ms/epoch - 5ms/step\n",
      "Epoch 22/10000\n",
      "14/14 - 0s - loss: 0.6893 - accuracy: 0.5452 - val_loss: 0.6948 - val_accuracy: 0.5196 - 67ms/epoch - 5ms/step\n",
      "Epoch 23/10000\n",
      "14/14 - 0s - loss: 0.6888 - accuracy: 0.5412 - val_loss: 0.6952 - val_accuracy: 0.5094 - 64ms/epoch - 5ms/step\n",
      "Epoch 24/10000\n",
      "14/14 - 0s - loss: 0.6894 - accuracy: 0.5445 - val_loss: 0.6950 - val_accuracy: 0.5210 - 65ms/epoch - 5ms/step\n",
      "Epoch 25/10000\n",
      "14/14 - 0s - loss: 0.6898 - accuracy: 0.5368 - val_loss: 0.6952 - val_accuracy: 0.5080 - 65ms/epoch - 5ms/step\n",
      "Epoch 26/10000\n",
      "14/14 - 0s - loss: 0.6898 - accuracy: 0.5387 - val_loss: 0.6949 - val_accuracy: 0.5181 - 66ms/epoch - 5ms/step\n",
      "Epoch 27/10000\n",
      "14/14 - 0s - loss: 0.6893 - accuracy: 0.5434 - val_loss: 0.6952 - val_accuracy: 0.5094 - 65ms/epoch - 5ms/step\n",
      "Epoch 28/10000\n",
      "14/14 - 0s - loss: 0.6885 - accuracy: 0.5445 - val_loss: 0.6952 - val_accuracy: 0.5239 - 66ms/epoch - 5ms/step\n",
      "Epoch 29/10000\n",
      "14/14 - 0s - loss: 0.6891 - accuracy: 0.5419 - val_loss: 0.6955 - val_accuracy: 0.5167 - 64ms/epoch - 5ms/step\n",
      "Epoch 30/10000\n",
      "14/14 - 0s - loss: 0.6882 - accuracy: 0.5336 - val_loss: 0.6954 - val_accuracy: 0.5196 - 64ms/epoch - 5ms/step\n",
      "Epoch 31/10000\n",
      "14/14 - 0s - loss: 0.6901 - accuracy: 0.5405 - val_loss: 0.6957 - val_accuracy: 0.5065 - 64ms/epoch - 5ms/step\n",
      "Epoch 32/10000\n",
      "14/14 - 0s - loss: 0.6876 - accuracy: 0.5405 - val_loss: 0.6954 - val_accuracy: 0.5167 - 64ms/epoch - 5ms/step\n",
      "Epoch 33/10000\n",
      "14/14 - 0s - loss: 0.6890 - accuracy: 0.5397 - val_loss: 0.6955 - val_accuracy: 0.5196 - 65ms/epoch - 5ms/step\n",
      "Epoch 34/10000\n",
      "14/14 - 0s - loss: 0.6898 - accuracy: 0.5376 - val_loss: 0.6958 - val_accuracy: 0.5094 - 67ms/epoch - 5ms/step\n",
      "Epoch 35/10000\n",
      "14/14 - 0s - loss: 0.6887 - accuracy: 0.5350 - val_loss: 0.6954 - val_accuracy: 0.5210 - 64ms/epoch - 5ms/step\n",
      "Epoch 36/10000\n",
      "14/14 - 0s - loss: 0.6884 - accuracy: 0.5278 - val_loss: 0.6959 - val_accuracy: 0.5152 - 66ms/epoch - 5ms/step\n",
      "Epoch 37/10000\n",
      "14/14 - 0s - loss: 0.6888 - accuracy: 0.5379 - val_loss: 0.6959 - val_accuracy: 0.5181 - 62ms/epoch - 4ms/step\n",
      "Epoch 38/10000\n",
      "14/14 - 0s - loss: 0.6883 - accuracy: 0.5459 - val_loss: 0.6961 - val_accuracy: 0.5167 - 64ms/epoch - 5ms/step\n",
      "Epoch 39/10000\n",
      "14/14 - 0s - loss: 0.6886 - accuracy: 0.5437 - val_loss: 0.6964 - val_accuracy: 0.5210 - 63ms/epoch - 4ms/step\n",
      "Epoch 40/10000\n",
      "14/14 - 0s - loss: 0.6903 - accuracy: 0.5328 - val_loss: 0.6964 - val_accuracy: 0.5152 - 65ms/epoch - 5ms/step\n",
      "Epoch 41/10000\n",
      "14/14 - 0s - loss: 0.6884 - accuracy: 0.5343 - val_loss: 0.6964 - val_accuracy: 0.5225 - 64ms/epoch - 5ms/step\n",
      "Epoch 42/10000\n",
      "14/14 - 0s - loss: 0.6885 - accuracy: 0.5390 - val_loss: 0.6963 - val_accuracy: 0.5181 - 63ms/epoch - 4ms/step\n",
      "Epoch 43/10000\n",
      "14/14 - 0s - loss: 0.6884 - accuracy: 0.5361 - val_loss: 0.6966 - val_accuracy: 0.5196 - 67ms/epoch - 5ms/step\n",
      "Epoch 44/10000\n",
      "14/14 - 0s - loss: 0.6877 - accuracy: 0.5397 - val_loss: 0.6976 - val_accuracy: 0.5196 - 65ms/epoch - 5ms/step\n",
      "Epoch 45/10000\n",
      "14/14 - 0s - loss: 0.6880 - accuracy: 0.5383 - val_loss: 0.6968 - val_accuracy: 0.5167 - 65ms/epoch - 5ms/step\n",
      "Epoch 46/10000\n",
      "14/14 - 0s - loss: 0.6875 - accuracy: 0.5426 - val_loss: 0.6972 - val_accuracy: 0.5225 - 66ms/epoch - 5ms/step\n",
      "Epoch 47/10000\n",
      "14/14 - 0s - loss: 0.6887 - accuracy: 0.5358 - val_loss: 0.6971 - val_accuracy: 0.5210 - 64ms/epoch - 5ms/step\n",
      "Epoch 48/10000\n",
      "14/14 - 0s - loss: 0.6891 - accuracy: 0.5350 - val_loss: 0.6967 - val_accuracy: 0.5210 - 65ms/epoch - 5ms/step\n",
      "Epoch 49/10000\n",
      "14/14 - 0s - loss: 0.6894 - accuracy: 0.5368 - val_loss: 0.6972 - val_accuracy: 0.5036 - 65ms/epoch - 5ms/step\n",
      "Epoch 50/10000\n",
      "14/14 - 0s - loss: 0.6883 - accuracy: 0.5383 - val_loss: 0.6969 - val_accuracy: 0.5065 - 64ms/epoch - 5ms/step\n",
      "Epoch 51/10000\n",
      "14/14 - 0s - loss: 0.6879 - accuracy: 0.5397 - val_loss: 0.6976 - val_accuracy: 0.5109 - 65ms/epoch - 5ms/step\n",
      "Epoch 52/10000\n",
      "14/14 - 0s - loss: 0.6883 - accuracy: 0.5434 - val_loss: 0.6971 - val_accuracy: 0.5181 - 66ms/epoch - 5ms/step\n",
      "Epoch 53/10000\n",
      "14/14 - 0s - loss: 0.6886 - accuracy: 0.5376 - val_loss: 0.6973 - val_accuracy: 0.5051 - 64ms/epoch - 5ms/step\n",
      "Epoch 54/10000\n",
      "14/14 - 0s - loss: 0.6887 - accuracy: 0.5408 - val_loss: 0.6973 - val_accuracy: 0.5065 - 63ms/epoch - 5ms/step\n",
      "Epoch 55/10000\n",
      "14/14 - 0s - loss: 0.6891 - accuracy: 0.5310 - val_loss: 0.6972 - val_accuracy: 0.5051 - 65ms/epoch - 5ms/step\n",
      "Epoch 56/10000\n",
      "14/14 - 0s - loss: 0.6870 - accuracy: 0.5437 - val_loss: 0.6974 - val_accuracy: 0.5152 - 64ms/epoch - 5ms/step\n",
      "27/27 [==============================] - 0s 762us/step\n",
      "['Label', 'Close']\n",
      "train_X Shape: (3444, 10, 2)\n",
      "train_y Shape: (3444, 2)\n",
      "test_X Shape: (862, 10, 2)\n",
      "test_y Shape: (862,)\n",
      "Epoch 1/10000\n",
      "14/14 - 1s - loss: 0.6984 - accuracy: 0.4846 - val_loss: 0.6948 - val_accuracy: 0.4877 - 513ms/epoch - 37ms/step\n",
      "Epoch 2/10000\n",
      "14/14 - 0s - loss: 0.6967 - accuracy: 0.4799 - val_loss: 0.6935 - val_accuracy: 0.4978 - 67ms/epoch - 5ms/step\n",
      "Epoch 3/10000\n",
      "14/14 - 0s - loss: 0.6950 - accuracy: 0.4791 - val_loss: 0.6934 - val_accuracy: 0.4862 - 67ms/epoch - 5ms/step\n",
      "Epoch 4/10000\n",
      "14/14 - 0s - loss: 0.6934 - accuracy: 0.5078 - val_loss: 0.6930 - val_accuracy: 0.5094 - 65ms/epoch - 5ms/step\n",
      "Epoch 5/10000\n",
      "14/14 - 0s - loss: 0.6935 - accuracy: 0.5074 - val_loss: 0.6928 - val_accuracy: 0.5225 - 66ms/epoch - 5ms/step\n",
      "Epoch 6/10000\n",
      "14/14 - 0s - loss: 0.6930 - accuracy: 0.4984 - val_loss: 0.6927 - val_accuracy: 0.5283 - 66ms/epoch - 5ms/step\n",
      "Epoch 7/10000\n",
      "14/14 - 0s - loss: 0.6923 - accuracy: 0.5172 - val_loss: 0.6926 - val_accuracy: 0.5312 - 68ms/epoch - 5ms/step\n",
      "Epoch 8/10000\n",
      "14/14 - 0s - loss: 0.6912 - accuracy: 0.5281 - val_loss: 0.6930 - val_accuracy: 0.5210 - 67ms/epoch - 5ms/step\n",
      "Epoch 9/10000\n",
      "14/14 - 0s - loss: 0.6911 - accuracy: 0.5230 - val_loss: 0.6928 - val_accuracy: 0.5210 - 69ms/epoch - 5ms/step\n",
      "Epoch 10/10000\n",
      "14/14 - 0s - loss: 0.6919 - accuracy: 0.5194 - val_loss: 0.6928 - val_accuracy: 0.5283 - 71ms/epoch - 5ms/step\n",
      "Epoch 11/10000\n",
      "14/14 - 0s - loss: 0.6909 - accuracy: 0.5270 - val_loss: 0.6930 - val_accuracy: 0.5254 - 70ms/epoch - 5ms/step\n",
      "Epoch 12/10000\n",
      "14/14 - 0s - loss: 0.6904 - accuracy: 0.5274 - val_loss: 0.6930 - val_accuracy: 0.5269 - 70ms/epoch - 5ms/step\n",
      "Epoch 13/10000\n",
      "14/14 - 0s - loss: 0.6908 - accuracy: 0.5361 - val_loss: 0.6933 - val_accuracy: 0.5225 - 67ms/epoch - 5ms/step\n",
      "Epoch 14/10000\n",
      "14/14 - 0s - loss: 0.6915 - accuracy: 0.5285 - val_loss: 0.6932 - val_accuracy: 0.5225 - 69ms/epoch - 5ms/step\n",
      "Epoch 15/10000\n",
      "14/14 - 0s - loss: 0.6912 - accuracy: 0.5307 - val_loss: 0.6934 - val_accuracy: 0.5181 - 69ms/epoch - 5ms/step\n",
      "Epoch 16/10000\n",
      "14/14 - 0s - loss: 0.6902 - accuracy: 0.5299 - val_loss: 0.6934 - val_accuracy: 0.5269 - 68ms/epoch - 5ms/step\n",
      "Epoch 17/10000\n",
      "14/14 - 0s - loss: 0.6899 - accuracy: 0.5318 - val_loss: 0.6936 - val_accuracy: 0.5123 - 68ms/epoch - 5ms/step\n",
      "Epoch 18/10000\n",
      "14/14 - 0s - loss: 0.6907 - accuracy: 0.5285 - val_loss: 0.6937 - val_accuracy: 0.5109 - 68ms/epoch - 5ms/step\n",
      "Epoch 19/10000\n",
      "14/14 - 0s - loss: 0.6898 - accuracy: 0.5339 - val_loss: 0.6938 - val_accuracy: 0.5109 - 69ms/epoch - 5ms/step\n",
      "Epoch 20/10000\n",
      "14/14 - 0s - loss: 0.6898 - accuracy: 0.5292 - val_loss: 0.6941 - val_accuracy: 0.5123 - 68ms/epoch - 5ms/step\n",
      "Epoch 21/10000\n",
      "14/14 - 0s - loss: 0.6890 - accuracy: 0.5477 - val_loss: 0.6943 - val_accuracy: 0.5051 - 66ms/epoch - 5ms/step\n",
      "Epoch 22/10000\n",
      "14/14 - 0s - loss: 0.6893 - accuracy: 0.5321 - val_loss: 0.6944 - val_accuracy: 0.5065 - 67ms/epoch - 5ms/step\n",
      "Epoch 23/10000\n",
      "14/14 - 0s - loss: 0.6898 - accuracy: 0.5365 - val_loss: 0.6944 - val_accuracy: 0.5109 - 69ms/epoch - 5ms/step\n",
      "Epoch 24/10000\n",
      "14/14 - 0s - loss: 0.6896 - accuracy: 0.5252 - val_loss: 0.6947 - val_accuracy: 0.5051 - 74ms/epoch - 5ms/step\n",
      "Epoch 25/10000\n",
      "14/14 - 0s - loss: 0.6897 - accuracy: 0.5379 - val_loss: 0.6945 - val_accuracy: 0.5094 - 77ms/epoch - 6ms/step\n",
      "Epoch 26/10000\n",
      "14/14 - 0s - loss: 0.6894 - accuracy: 0.5318 - val_loss: 0.6944 - val_accuracy: 0.5167 - 69ms/epoch - 5ms/step\n",
      "Epoch 27/10000\n",
      "14/14 - 0s - loss: 0.6897 - accuracy: 0.5343 - val_loss: 0.6946 - val_accuracy: 0.5094 - 70ms/epoch - 5ms/step\n",
      "Epoch 28/10000\n",
      "14/14 - 0s - loss: 0.6887 - accuracy: 0.5365 - val_loss: 0.6947 - val_accuracy: 0.5138 - 70ms/epoch - 5ms/step\n",
      "Epoch 29/10000\n",
      "14/14 - 0s - loss: 0.6900 - accuracy: 0.5387 - val_loss: 0.6951 - val_accuracy: 0.5022 - 70ms/epoch - 5ms/step\n",
      "Epoch 30/10000\n",
      "14/14 - 0s - loss: 0.6897 - accuracy: 0.5376 - val_loss: 0.6947 - val_accuracy: 0.5167 - 73ms/epoch - 5ms/step\n",
      "Epoch 31/10000\n",
      "14/14 - 0s - loss: 0.6903 - accuracy: 0.5328 - val_loss: 0.6954 - val_accuracy: 0.5065 - 71ms/epoch - 5ms/step\n",
      "Epoch 32/10000\n",
      "14/14 - 0s - loss: 0.6883 - accuracy: 0.5270 - val_loss: 0.6952 - val_accuracy: 0.5109 - 109ms/epoch - 8ms/step\n",
      "Epoch 33/10000\n",
      "14/14 - 0s - loss: 0.6897 - accuracy: 0.5328 - val_loss: 0.6951 - val_accuracy: 0.5167 - 88ms/epoch - 6ms/step\n",
      "Epoch 34/10000\n",
      "14/14 - 0s - loss: 0.6889 - accuracy: 0.5419 - val_loss: 0.6957 - val_accuracy: 0.5065 - 72ms/epoch - 5ms/step\n",
      "Epoch 35/10000\n",
      "14/14 - 0s - loss: 0.6894 - accuracy: 0.5368 - val_loss: 0.6951 - val_accuracy: 0.5254 - 70ms/epoch - 5ms/step\n",
      "Epoch 36/10000\n",
      "14/14 - 0s - loss: 0.6882 - accuracy: 0.5394 - val_loss: 0.6957 - val_accuracy: 0.5065 - 68ms/epoch - 5ms/step\n",
      "Epoch 37/10000\n",
      "14/14 - 0s - loss: 0.6885 - accuracy: 0.5390 - val_loss: 0.6955 - val_accuracy: 0.5196 - 68ms/epoch - 5ms/step\n",
      "Epoch 38/10000\n",
      "14/14 - 0s - loss: 0.6892 - accuracy: 0.5408 - val_loss: 0.6956 - val_accuracy: 0.5196 - 70ms/epoch - 5ms/step\n",
      "Epoch 39/10000\n",
      "14/14 - 0s - loss: 0.6882 - accuracy: 0.5394 - val_loss: 0.6961 - val_accuracy: 0.5094 - 70ms/epoch - 5ms/step\n",
      "Epoch 40/10000\n",
      "14/14 - 0s - loss: 0.6892 - accuracy: 0.5328 - val_loss: 0.6961 - val_accuracy: 0.5123 - 72ms/epoch - 5ms/step\n",
      "Epoch 41/10000\n",
      "14/14 - 0s - loss: 0.6898 - accuracy: 0.5314 - val_loss: 0.6960 - val_accuracy: 0.5109 - 75ms/epoch - 5ms/step\n",
      "Epoch 42/10000\n",
      "14/14 - 0s - loss: 0.6881 - accuracy: 0.5452 - val_loss: 0.6960 - val_accuracy: 0.5225 - 73ms/epoch - 5ms/step\n",
      "Epoch 43/10000\n",
      "14/14 - 0s - loss: 0.6887 - accuracy: 0.5452 - val_loss: 0.6963 - val_accuracy: 0.5181 - 71ms/epoch - 5ms/step\n",
      "Epoch 44/10000\n",
      "14/14 - 0s - loss: 0.6876 - accuracy: 0.5477 - val_loss: 0.6970 - val_accuracy: 0.5094 - 71ms/epoch - 5ms/step\n",
      "Epoch 45/10000\n",
      "14/14 - 0s - loss: 0.6888 - accuracy: 0.5383 - val_loss: 0.6963 - val_accuracy: 0.5283 - 71ms/epoch - 5ms/step\n",
      "Epoch 46/10000\n",
      "14/14 - 0s - loss: 0.6887 - accuracy: 0.5387 - val_loss: 0.6968 - val_accuracy: 0.5138 - 69ms/epoch - 5ms/step\n",
      "Epoch 47/10000\n",
      "14/14 - 0s - loss: 0.6888 - accuracy: 0.5456 - val_loss: 0.6966 - val_accuracy: 0.5210 - 68ms/epoch - 5ms/step\n",
      "Epoch 48/10000\n",
      "14/14 - 0s - loss: 0.6894 - accuracy: 0.5325 - val_loss: 0.6966 - val_accuracy: 0.5167 - 66ms/epoch - 5ms/step\n",
      "Epoch 49/10000\n",
      "14/14 - 0s - loss: 0.6897 - accuracy: 0.5267 - val_loss: 0.6967 - val_accuracy: 0.5109 - 67ms/epoch - 5ms/step\n",
      "Epoch 50/10000\n",
      "14/14 - 0s - loss: 0.6892 - accuracy: 0.5405 - val_loss: 0.6970 - val_accuracy: 0.5080 - 67ms/epoch - 5ms/step\n",
      "Epoch 51/10000\n",
      "14/14 - 0s - loss: 0.6888 - accuracy: 0.5372 - val_loss: 0.6968 - val_accuracy: 0.5123 - 69ms/epoch - 5ms/step\n",
      "Epoch 52/10000\n",
      "14/14 - 0s - loss: 0.6886 - accuracy: 0.5408 - val_loss: 0.6968 - val_accuracy: 0.5210 - 67ms/epoch - 5ms/step\n",
      "Epoch 53/10000\n",
      "14/14 - 0s - loss: 0.6887 - accuracy: 0.5347 - val_loss: 0.6970 - val_accuracy: 0.5138 - 67ms/epoch - 5ms/step\n",
      "Epoch 54/10000\n",
      "14/14 - 0s - loss: 0.6885 - accuracy: 0.5452 - val_loss: 0.6976 - val_accuracy: 0.5094 - 70ms/epoch - 5ms/step\n",
      "Epoch 55/10000\n",
      "14/14 - 0s - loss: 0.6885 - accuracy: 0.5368 - val_loss: 0.6973 - val_accuracy: 0.5181 - 70ms/epoch - 5ms/step\n",
      "Epoch 56/10000\n",
      "14/14 - 0s - loss: 0.6881 - accuracy: 0.5437 - val_loss: 0.6976 - val_accuracy: 0.5167 - 69ms/epoch - 5ms/step\n",
      "Epoch 57/10000\n",
      "14/14 - 0s - loss: 0.6879 - accuracy: 0.5372 - val_loss: 0.6975 - val_accuracy: 0.5181 - 71ms/epoch - 5ms/step\n",
      "27/27 [==============================] - 0s 798us/step\n",
      "Model saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vp/8_rd4_c56g3dpqb1167z6tqr0000gn/T/ipykernel_66868/3958443450.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append({\"timestep\": step,\"features\": data.columns.values,\"google_trends_lag\":g,\"tweet_volume_lag\": tv,\"tweet_polarity_score_lag\": tw_lag, \"batch_size\":b, \"neurons\":n, \"layers\":l, \"mean_down_f1_score\":mean_down_f1_score,\"mean_up_f1_score\":mean_up_f1_score, \"mean_acc\": mean_acc,\"min_acc\":min_acc, \"max_acc\":max_acc, \"diff_acc\": diff_acc,\"optimizer\":my_optimizer,\"month\":month,\"consecutive\": flag,\"actic_func\":activ_func}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "filepath_out='./../data/lstm_results.csv'\n",
    "results=test_model(filepath_out, feature_conditions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "results.to_csv(filepath_out, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}